{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is my personal wiki where I share everything I know about this world in form of an online MkDocs book hosted on GitHub . If this is your first time visiting this wiki, take a look at meta , as it describes this wiki, its structure and goals in more detail. Using the wiki well \u00b6 You can quickly search the contents of this wiki above or you can explore the tree view to the left. Start with the first article that grabs your attention and be ready to incrementally read the rest. Or you can use it as a reference, cloning the git repository and using grep. Make your own wiki \u00b6 Don't be afraid to create one of your own and share what you know with the world. If you don't want to build your own, I invite you to use a fork of mine and make contributions . I would love to see the blue-book maintained by several people. You can view other similar continuously updated wikis to get inspiration. Contributing \u00b6 If you find a mistake anywhere in this wiki or want to add new content, I'll be glad to accept your contribution. You can quickly find any entry you wish to edit by searching for the topic or use the edit button on the top right of any article to add your changes with a PR. I also appreciate any ideas you have on how I can improve this wiki. And if you don't want to go through the hassle of building your own, you can use mine Thank you \u00b6 If you liked my book and want to make me happy, please see if you know how could I fulfill any item of my wish list or see if you want to contribute to my other projects .","title":"Introduction"},{"location":"#using-the-wiki-well","text":"You can quickly search the contents of this wiki above or you can explore the tree view to the left. Start with the first article that grabs your attention and be ready to incrementally read the rest. Or you can use it as a reference, cloning the git repository and using grep.","title":"Using the wiki well"},{"location":"#make-your-own-wiki","text":"Don't be afraid to create one of your own and share what you know with the world. If you don't want to build your own, I invite you to use a fork of mine and make contributions . I would love to see the blue-book maintained by several people. You can view other similar continuously updated wikis to get inspiration.","title":"Make your own wiki"},{"location":"#contributing","text":"If you find a mistake anywhere in this wiki or want to add new content, I'll be glad to accept your contribution. You can quickly find any entry you wish to edit by searching for the topic or use the edit button on the top right of any article to add your changes with a PR. I also appreciate any ideas you have on how I can improve this wiki. And if you don't want to go through the hassle of building your own, you can use mine","title":"Contributing"},{"location":"#thank-you","text":"If you liked my book and want to make me happy, please see if you know how could I fulfill any item of my wish list or see if you want to contribute to my other projects .","title":"Thank you"},{"location":"contact/","text":"I'm available through: Email or XMPP at lyz@riseup.net . PGP Key: 6ADA882386CDF9BD1884534C6C7D7C1612CDE02F -----BEGIN PGP PUBLIC KEY BLOCK----- mQINBFhs5wUBEAC289UxruAPfjvJ723AKhUhRI0/fw+cG0IeSUJfOSvWW+HJ7Elo QoPkKYv6E1k4SzIt6AgbEWpL35PQP79aQ5BFog2SbfVvfnq1/gIasFlyeFX1BUTh zxTKrYKwbUdsTeMYw32v5p2Q+D8CZK6/0RCM/GSb5oMPVancOeoZs8IebKpJH2x7 HCniyQbq7xiFU5sUyB6tmgCiXg8INib+oTZqGKW/sVaxmTdH+fF9a2nnH0TN8h2W 5V5XQ9/VQZk/GHQVq/Y0Z73BibOJM5Bv+3r2EIJfozlpWdUblat45lSATBo/sktf YKlxwAztWPtcTavJ58F1ufGcUPjwGW4E92zRaozC+tpzd5QtHeYM7m6fGlXxckua UesZcZLl9pY4Bc8Mw40WvI1ibhA2mP2R5AO8hJ0vJyFfi35lqM/DJVV1900yp+em uY+u6bNJ1gLLb7QnhbV1VYLTSCoWzPQvWHgMHAKpAjO15rKAItXD17BM2eQgJMuX LcoWeOcz/MrMQiGKSkqpmapwgtDZ5t81D2qWv+wsaZgcO/erknugHFmR3kAP8YHp JsIpaYY7kj+yVJb92uzZKQAEaUpq3uRsBDtkoC2MPzKN4fgWa8f4jBpIzxuBTd+6 75sVq5VB5eaq3w4J0Z4kbk1DVyNffv3LeZCv9oC2mb1aXyVD/gWHlPD+6wARAQAB tBZseXouLiA8bHl6QHJpc2V1cC5uZXQ+iQJUBBMBCAA+AhsDBQsJCAcCBhUICQoL AgQWAgMBAh4BAheAFiEEatqII4bN+b0YhFNMbH18FhLN4C8FAl4XCTwFCQeLVbcA CgkQbH18FhLN4C/Jkw//Th/tAagxBchztzA2bAJog7sd3FK4hH2cqGFdBG+yx5TW 2ywfDXjTXVeKhHxkSnZZgxO0U31W2Fv+tLmRKN8MrvGSjIpUlWTmeaIG1W+ftlcG NrR+CDL0lrkKZnyQGJhe675lNoo2FKQ/37B/NIyzfIWw8eZStYabHtj5H40nti1k riwZsk76+kR6FI1EVKCGGmo/Spl/VX9MuWNjg9E0cJvpzKY05gKmFSuMJwxVhrFV ly0MhZS+4xddbCMaBo2OJEDrcFBQgBiUnxS8PcADLK7zn3zpemcJm5/8T/DyQHeY 0Yh76KJ92aIB7eLLnRnRcvCXt0RZ+s3sHqLgrsT3OV0jlC7GLjTBgTe6qGH3Lr/h whiOp6g1k125+v20fKPWDlGar3sdSD/ZjJDeAHedV5I3QVT6zorUYcQYb6vYPlOU aq7k0jLjGuoxHQeXGAZMvlKQfgHDfiwBwyIX6D24wsyr+XDnrVyDoCO654OqYcUH wK1y57NbUOpzvD+ZEO/8aKeBUh0zKz682hsA8HJT8G09UBcs36HAnbTkp+rPxgTH eBVcTYLi/CFy9tXOhBmyPhxrILsPwmOvZA4tg7LLnj2P2qdk2Gz1si/D8s2Afr+c re9pidcYbiXJI+Pnw+e9Pylf/1WM8MS5Z2W9Liyc29/kLsCL8Dp0eJtqzJLAX0y5 Ag0EWGznBQEQALNL9sNc4SytS3fOcS4gHvZpH3TLJ6o0K/Lxg4RfkLMebDJwWvSW mjQLv3GqRfOhGj2Osi2YukFIJb4vxPJFO7wQhCi5LLSVEb5d/z9ZOJUdGdI9JvGW dFDuLEXwDnJaP5Jmjm3DwbvHK+goI7Fn3TKc27iqOVAKVIjWNPaqFZxwIE9o/+1c 3bTk3A8WOBmcv1IaxsUNkRDOFJlQYLM/bFIuDD+cW/CcYro8ouC9aekmvTDoRaU5 xv++fXtesn6Cy+xBgvBGIIXGo5xzd6Y66Yf8uNpuJXo9Dc6rApH1QEQNwZX1cxvG UpQx+9JNF0eptDLvTgmxcCglllrylcw8ZsVEt6BTgrCd2JXMGxUcAnhXpRWRmXNL n97FOBb6OBd6k7DC6QCiVKr7sytq1Ywl8GTtWrTP7sK+/+KDLPJ/oY7+bwV94+N8 Gthr94njNqb5G6t9fqQ/+cJv7oF8DoBvylYGqm2hvYpOH53hMq1y3OTPoFKP6AIx twIWHkdmMALm6a6bxAetGQxiaPZTOduJDehwiF9EUkiNhpESMl3I2+vH86jV2IiT 4BuUqGBU5wrAN/FixIRlmaSUX7e0OkUkDexVlpw5poJbPEbvhOtuj/V9BOxQKWB4 bjXMHEHR5YcJ1lhPjFFM3pqOz6ZaN8Hs70KOBE+/3/c1hS5debWPBMdlABEBAAGJ AjwEGAEIACYCGwwWIQRq2ogjhs35vRiEU0xsfXwWEs3gLwUCXhcJRgUJB4tVwQAK CRBsfXwWEs3gL41DEACYtc6mykbhZh2eWrdNynbYX1TNYFH+4BP+zpN8kNHPwKfX IypLLSSwUhYdZ9kb8WB8n4cH8njk4P1LyGtfUOxbEpKCQNXfW3aWDDsZunxdSkyc 3opaCo2w/Gf2ynxtbJVWoNWYn8fDQJcE3UAz8+rioHGRUCBF//G8VWdqZ4PCARGu TPeurJG5aljJGqlrvAXewqNItGEoARHGC3R9otSC8Y5cd9zL3iKUnBh9xhiqFzjK /7J9uQcDz6GTzZKxDqRQmcs27nGjWFNscZY16dBDj6y2d+v+RJEgFY9uW7KGVfFG Y9kPsSKdKUzeE+TOvwintakMQT26dNWBbUkDkMt08kEFk5SyeoQcjnqWMFJgrav1 RYUwz/UFuWep0y9Rt0PrW40mBZOd4roRdgEX6I65K6CC38u/nIgJRG2I/2LkWIwu n2LROOQ+0O6rn4HObgfoEZE03K6AW1DyNR6BnspbTDt0fRIDk6Rrfw6Xe1AfANrK 9zs95WbKkbydE1xFddOJ10qDleFOOaeCWp7KW1GkvEKfoRXhhAo/xnFpjHbGuvJv bTL4pYkaoOyGriAn3fZ8zOoBLspuAzEENBLtX41XU8PFjwcRu4GfFSrP03svi3km WodDQhjSPW+B/9SmLj+UkaIUlTTqwAs8rHtexkzlIhHGASXc+Iuuz5JuzUlPUw== =9EvG -----END PGP PUBLIC KEY BLOCK----- Through Github by opening an issue .","title":"Contact"},{"location":"life_automation/life_automation/","text":"Life Automation is the act of analyzing your interactions with the world to find ways to reduce the time or willpower spent on unwanted processes. Once you've covered some minimum life requirements (health, money or happiness), time is your most valued asset. It's sad to waste it doing stuff that we need but don't increase our happiness. So the idea is to identify which are those processes and find optimizations that allows us to do them in less time or using less willpower. I've also faced the problem of having so much stuff in my mind. Having background processes increase your brain load and are a constant sink of willpower. As a result, when you really need that CPU time, your brain is tired and doesn't work to it's full performance. Automating processes, like life logging and task management, allows you to delegate those worries. Life automation can lead to habit building, which reduces even more the willpower consumption of processes, at the same time it reduces the error rate. Automating home chores \u00b6 Using grocy to maintain the house stock, shopping lists and meal plans.","title":"Introduction"},{"location":"life_automation/life_automation/#automating-home-chores","text":"Using grocy to maintain the house stock, shopping lists and meal plans.","title":"Automating home chores"},{"location":"meta/meta/","text":"In this book you'll find, in a wiki format, all the notes I made on a huge variety of topics, such as, Linux, DevSecOps, feminism, rationalism, life automation , productivity or programming. The main goal is to store all the knowledge gathered throughout my life in a way that everyone can benefit from reading it or referencing in an easy and quickly way. I will be updating this wiki quite often as I use it myself daily both to keep an account of things I know as well as things I want to know and everything in between. History \u00b6 I've tried writing blogs in the past, but it doesn't work for me. I can't stand the idea of having to save some time to sit and write a full article of something I've done. I need to document at the same time as I develop or learn. Furthermore, as I usually use incremental reading or work on several projects, I don't write one article, but improve several at the same time in a unordered way. That's why I embrace Gwern's Long Content principle . The only drawback of this format is that I won't have an interesting RSS feed. You could go through the git log but it doesn't make any sense. That's why I'm thinking of generating a monthly newsletter similar to Gwern's Newsletters or Changelog . In 2016 I started writing in text files summaries of different concepts, how to install or how to use tools. In the beginning it was plaintext, then came Markdown , then Asciidoc , I did several refactors to reorder the different articles based in different structured ways, but I always did it with myself as the only target audience. Three years, 7422 articles and almost 50 million lines later, I found Gwern's website and Nikita's wiki , which made me think that it was time to do another refactor to give my wiki a semantical structure, go beyond a simple reference making it readable and open it to the internet. And the blue book was born. Book structure \u00b6 Each directory is a topic that can include other subtopics under it related to the parent topic. As sometimes the strict hierarchical structure of the categories doesn't work, I also use tags to link articles. If this is your first time visiting this wiki, you can just start reading from the top entry down and see what sparks your interest. Content Structure \u00b6 Each topic will have a title, some description of it, usually my own thoughts and knowledge on it as well as referencing some resources or links I have liked or used that helped me either understand the topic or gain appreciation of it. The structure of each of the posts will often look roughly like this: Title Description - My thoughts on the topic. Subtopics - Various subtopics related to the main topic. Notes - My own personal notes on the matter as well as things I found interesting on the internet regarding the topic. I often give a link of where I got things from. Links - Links related to the topic. Links \u00b6 My blue book is heavily inspired in this two other second brains: Gwern's website Nikita's wiki","title":"Meta"},{"location":"meta/meta/#history","text":"I've tried writing blogs in the past, but it doesn't work for me. I can't stand the idea of having to save some time to sit and write a full article of something I've done. I need to document at the same time as I develop or learn. Furthermore, as I usually use incremental reading or work on several projects, I don't write one article, but improve several at the same time in a unordered way. That's why I embrace Gwern's Long Content principle . The only drawback of this format is that I won't have an interesting RSS feed. You could go through the git log but it doesn't make any sense. That's why I'm thinking of generating a monthly newsletter similar to Gwern's Newsletters or Changelog . In 2016 I started writing in text files summaries of different concepts, how to install or how to use tools. In the beginning it was plaintext, then came Markdown , then Asciidoc , I did several refactors to reorder the different articles based in different structured ways, but I always did it with myself as the only target audience. Three years, 7422 articles and almost 50 million lines later, I found Gwern's website and Nikita's wiki , which made me think that it was time to do another refactor to give my wiki a semantical structure, go beyond a simple reference making it readable and open it to the internet. And the blue book was born.","title":"History"},{"location":"meta/meta/#book-structure","text":"Each directory is a topic that can include other subtopics under it related to the parent topic. As sometimes the strict hierarchical structure of the categories doesn't work, I also use tags to link articles. If this is your first time visiting this wiki, you can just start reading from the top entry down and see what sparks your interest.","title":"Book structure"},{"location":"meta/meta/#content-structure","text":"Each topic will have a title, some description of it, usually my own thoughts and knowledge on it as well as referencing some resources or links I have liked or used that helped me either understand the topic or gain appreciation of it. The structure of each of the posts will often look roughly like this: Title Description - My thoughts on the topic. Subtopics - Various subtopics related to the main topic. Notes - My own personal notes on the matter as well as things I found interesting on the internet regarding the topic. I often give a link of where I got things from. Links - Links related to the topic.","title":"Content Structure"},{"location":"meta/meta/#links","text":"My blue book is heavily inspired in this two other second brains: Gwern's website Nikita's wiki","title":"Links"},{"location":"projects/projects/","text":"Also known as where I'm spending my spare time. Home Stock inventory \u00b6 I try to follow the idea of emptying my mind as much as possible, so I'm able to spend my CPU time wisely. Keeping track of what do you have at home or what needs to be bought is an effort that should be avoided. So I'm integrating grocy in my life. Pydo \u00b6 I've been using Taskwarrior for the last five or six years. It's an awesome program to do task management and it is really customizable. So throughout these years I've done several scripts to integrate it into my workflow: Taskban : To do Sprint Reviews and do data analysis on the difference between the estimation and the actual time for doing tasks. To do so, I had to rewrite how tasklib stores task time information. Taskwarrior_recurrence : A group of hooks to fix Taskwarrior's recurrence issues . Taskwarrior_validation : A hook to help in the definition of validation criteria for tasks. Nevertheless, I'm searching for an alternative because: As the database grows, taskban becomes unusable. Taskwarrior lacks several features I want. It's written in C, which I don't speak. It's development has come to code maintenance only . It uses a plaintext file as data storage. tasklite is a promising project that tackles most of the points above. But is written in Haskel which I don't know and I don't want to learn. So taking my experience with taskwarrior and looking at tasklite, I've started building pydo . Blue book \u00b6 I'm refactoring all the knowledge gathered in the past in my cheat sheet repository into the blue book. This means migrating 7422 articles, almost 50 million lines, to the new structure. It's going to be a slow and painful process \u1559(\u21c0\u2038\u21bc\u2036)\u1557 . Clinv \u00b6 As part of my DevSecOps work, I need to have an updated inventory of cloud assets organized under a risk management framework. I did some research in the past and there was no tool that had: As you can see in how do you document your infrastructure? , there is still a void. Manage a dynamic inventory of risk management resources (Projects, Services, Information, People) and infrastructure resources (EC2, RDS, S3, Route53, IAM users, IAM groups\u2026). Add risk management metadata to your AWS resources. Monitor if there are resources that are not inside your inventory. Perform regular expression searches on all your resources. Get all your resources information. Works from the command line. So I started building clinv , Media indexation \u00b6 I've got a music collection of 136362 songs, belonging to mediarss downloads, bought CDs rips and friend library sharing. It is more less organized in a directory tree by genre, but I lack any library management features. I've got a lot of duplicates, incoherent naming scheme, no way of filtering or intelligent playlist generation. playlist_generator helped me with the last point, based on the metadata gathered with mep , but it's still not enough. So I'm in my way of migrate all the library to beets , and then I'll deprecate mep in favor to an mpd client that allows me to keep on saving the same metadata. Once it's implemented, I'll migrate all the metadata to the new system. Projects I maintain \u00b6 Mediarss \u00b6 I've always wanted to own the music I listen, because I don't want to give my data to the companies host the streaming services, nor I trust that they'll keep on giving the service . So I started building some small bash scrappers (I wasn't yet introduced to Python ) to get the media. That's when I learned to hate the web developers for their constant changes and to love the API. Then I discovered youtube-dl , a Python command-line program to download video or music from streaming sites. But I still laked the ability to stay updated with the artist channels. So mediarss was born. A youtube-dl wrapper to periodically download new content. This way, instead of using Youtube, Soundcloud or Bandcamp subscriptions, I've got a YAML with all the links that I want to monitor. Playlist_generator \u00b6 When my music library started growing due to mediarss , I wanted to generate playlists filtering my content by: Rating score fetched with mep . First time/last listened. Never listened songs. The playlists I usually generate with these filters are: Random unheard songs. Songs discovered last month/year with a rating score greater than X. Songs that I haven't heard since 20XX with a rating score greater than X (this one gave me pleasant surprises ^^). mep \u00b6 I started life logging with mep . One of the first programs I wrote when learning Bash . It is a mplayer wrapper that allows me to control it with i3 key bindings and store metadata of the music I listen. I don't even publish it because it's a horrible program that would make your eyes bleed. 600 lines of code, only 3 functions, 6 levels of nested ifs, no tests at all, but hey, the functions have docstrings! (\uff4f\u30fb_\u30fb)\u30ce\u201d(\u1d17_ \u1d17\u3002) The thing is that it works, so I everyday close my eyes and open my ears, waiting for a solution that gives me the same features with mpd .","title":"Projects"},{"location":"projects/projects/#home-stock-inventory","text":"I try to follow the idea of emptying my mind as much as possible, so I'm able to spend my CPU time wisely. Keeping track of what do you have at home or what needs to be bought is an effort that should be avoided. So I'm integrating grocy in my life.","title":"Home Stock inventory"},{"location":"projects/projects/#pydo","text":"I've been using Taskwarrior for the last five or six years. It's an awesome program to do task management and it is really customizable. So throughout these years I've done several scripts to integrate it into my workflow: Taskban : To do Sprint Reviews and do data analysis on the difference between the estimation and the actual time for doing tasks. To do so, I had to rewrite how tasklib stores task time information. Taskwarrior_recurrence : A group of hooks to fix Taskwarrior's recurrence issues . Taskwarrior_validation : A hook to help in the definition of validation criteria for tasks. Nevertheless, I'm searching for an alternative because: As the database grows, taskban becomes unusable. Taskwarrior lacks several features I want. It's written in C, which I don't speak. It's development has come to code maintenance only . It uses a plaintext file as data storage. tasklite is a promising project that tackles most of the points above. But is written in Haskel which I don't know and I don't want to learn. So taking my experience with taskwarrior and looking at tasklite, I've started building pydo .","title":"Pydo"},{"location":"projects/projects/#blue-book","text":"I'm refactoring all the knowledge gathered in the past in my cheat sheet repository into the blue book. This means migrating 7422 articles, almost 50 million lines, to the new structure. It's going to be a slow and painful process \u1559(\u21c0\u2038\u21bc\u2036)\u1557 .","title":"Blue book"},{"location":"projects/projects/#clinv","text":"As part of my DevSecOps work, I need to have an updated inventory of cloud assets organized under a risk management framework. I did some research in the past and there was no tool that had: As you can see in how do you document your infrastructure? , there is still a void. Manage a dynamic inventory of risk management resources (Projects, Services, Information, People) and infrastructure resources (EC2, RDS, S3, Route53, IAM users, IAM groups\u2026). Add risk management metadata to your AWS resources. Monitor if there are resources that are not inside your inventory. Perform regular expression searches on all your resources. Get all your resources information. Works from the command line. So I started building clinv ,","title":"Clinv"},{"location":"projects/projects/#media-indexation","text":"I've got a music collection of 136362 songs, belonging to mediarss downloads, bought CDs rips and friend library sharing. It is more less organized in a directory tree by genre, but I lack any library management features. I've got a lot of duplicates, incoherent naming scheme, no way of filtering or intelligent playlist generation. playlist_generator helped me with the last point, based on the metadata gathered with mep , but it's still not enough. So I'm in my way of migrate all the library to beets , and then I'll deprecate mep in favor to an mpd client that allows me to keep on saving the same metadata. Once it's implemented, I'll migrate all the metadata to the new system.","title":"Media indexation"},{"location":"projects/projects/#projects-i-maintain","text":"","title":"Projects I maintain"},{"location":"projects/projects/#mediarss","text":"I've always wanted to own the music I listen, because I don't want to give my data to the companies host the streaming services, nor I trust that they'll keep on giving the service . So I started building some small bash scrappers (I wasn't yet introduced to Python ) to get the media. That's when I learned to hate the web developers for their constant changes and to love the API. Then I discovered youtube-dl , a Python command-line program to download video or music from streaming sites. But I still laked the ability to stay updated with the artist channels. So mediarss was born. A youtube-dl wrapper to periodically download new content. This way, instead of using Youtube, Soundcloud or Bandcamp subscriptions, I've got a YAML with all the links that I want to monitor.","title":"Mediarss"},{"location":"projects/projects/#playlist_generator","text":"When my music library started growing due to mediarss , I wanted to generate playlists filtering my content by: Rating score fetched with mep . First time/last listened. Never listened songs. The playlists I usually generate with these filters are: Random unheard songs. Songs discovered last month/year with a rating score greater than X. Songs that I haven't heard since 20XX with a rating score greater than X (this one gave me pleasant surprises ^^).","title":"Playlist_generator"},{"location":"projects/projects/#mep","text":"I started life logging with mep . One of the first programs I wrote when learning Bash . It is a mplayer wrapper that allows me to control it with i3 key bindings and store metadata of the music I listen. I don't even publish it because it's a horrible program that would make your eyes bleed. 600 lines of code, only 3 functions, 6 levels of nested ifs, no tests at all, but hey, the functions have docstrings! (\uff4f\u30fb_\u30fb)\u30ce\u201d(\u1d17_ \u1d17\u3002) The thing is that it works, so I everyday close my eyes and open my ears, waiting for a solution that gives me the same features with mpd .","title":"mep"},{"location":"tags.html","text":"Contents grouped by tag \u00b6 Life Automation \u00b6 Life Automation","title":"Tags"},{"location":"tags.html#contents-grouped-by-tag","text":"","title":"Contents grouped by tag"},{"location":"tags.html#life-automation","text":"Life Automation","title":"Life Automation"}]}